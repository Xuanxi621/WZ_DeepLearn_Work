{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3459e2c8-34dd-4fde-8e19-36f6ef5cd31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å½“å‰è®¾å¤‡ï¼šcuda\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import random\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"âœ… å½“å‰è®¾å¤‡ï¼š{device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1d7a1-cb00-49ce-bfac-b2b32145f0de",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0a48b8-c5ee-4f09-bd51-c39b70bdc935",
   "metadata": {},
   "source": [
    "### BirdCNN - åŸºç¡€å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46f4f41e-be3d-4915-8403-5a504bc6db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    é¸Ÿç±»è¯†åˆ«CNNæ¨¡å‹\n",
    "    é€‚é…224x224è¾“å…¥å°ºå¯¸ï¼Œæ”¯æŒè‡ªå®šä¹‰ç±»åˆ«æ•°é‡\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(BirdCNN, self).__init__()\n",
    "\n",
    "        # ===== å·ç§¯å±‚å †å  =====\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, 1, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout2d(p=0.25)\n",
    "\n",
    "        # ===== å…¨è¿æ¥å±‚ =====\n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n",
    "        self.fc1_bn = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc2_bn = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # --- å·ç§¯å—1 ---\n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), 2)\n",
    "        # --- å·ç§¯å—2 ---\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), 2)\n",
    "        # --- å·ç§¯å—3 ---\n",
    "        x = self.dropout(F.max_pool2d(F.relu(self.bn3(self.conv3(x))), 2))\n",
    "        # --- å·ç§¯å—4 ---\n",
    "        x = F.max_pool2d(F.relu(self.bn4(self.conv4(x))), 2)\n",
    "        x = F.max_pool2d(x, 2)  # -> [batch, 128, 7, 7]\n",
    "\n",
    "        # --- å±•å¹³ + å…¨è¿æ¥ ---\n",
    "        x = x.view(-1, 128 * 7 * 7)\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e5a98-f764-4d3a-9bc1-7ef05df9a1ec",
   "metadata": {},
   "source": [
    "### BirdCNN_Optimal â€” é’ˆå¯¹ä¸­å°è§„æ¨¡æ•°æ®é›†ä¼˜åŒ–æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23601966-dae3-4f8a-9c51-061bf280d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCNN_Optimal(nn.Module):\n",
    "    \"\"\"\n",
    "    é’ˆå¯¹3000å·¦å³å¼ å›¾ç‰‡çš„ä¼˜åŒ–æ¨¡å‹ - é¿å…è¿‡æ‹ŸåˆåŒæ—¶å¢å¼ºç‰¹å¾æå–\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(BirdCNN_Optimal, self).__init__()\n",
    "\n",
    "        # ===== å·ç§¯æ¨¡å— =====\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv3_extra = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        self.bn3_extra = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, 1, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout_conv = nn.Dropout2d(p=0.3)\n",
    "        self.dropout_fc = nn.Dropout(p=0.5)\n",
    "\n",
    "        # ===== å…¨è¿æ¥å±‚ =====\n",
    "        self.fc1 = nn.Linear(256 * 7 * 7, 512)\n",
    "        self.fc1_bn = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc2_bn = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), 2)\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn3_extra(self.conv3_extra(x)))\n",
    "        x = self.dropout_conv(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = F.max_pool2d(F.relu(self.bn4(self.conv4(x))), 4)\n",
    "        x = x.view(-1, 256 * 7 * 7)\n",
    "\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = self.dropout_fc(x)\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f603c3-cb6e-45cb-89a7-f5504e32ae87",
   "metadata": {},
   "source": [
    "### BirdResNet â€” æ®‹å·®ç»“æ„CNNæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46400495-1246-461d-9e53-8b83535a5ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    æ®‹å·®å— - ä¿æŒè¾“å…¥è¾“å‡ºå°ºå¯¸ç›¸åŒ\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        # ä¸»è·¯å¾„\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # æ·å¾„è·¯å¾„ï¼ˆå¦‚æœéœ€è¦è°ƒæ•´å°ºå¯¸ï¼‰\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "        self.dropout = nn.Dropout2d(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ä¸»è·¯å¾„\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # æ·å¾„è·¯å¾„\n",
    "        shortcut = self.shortcut(x)\n",
    "\n",
    "        # æ®‹å·®è¿æ¥\n",
    "        out += shortcut\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class BirdResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    é¸Ÿç±»è¯†åˆ«æ®‹å·®ç½‘ç»œ - ç»“åˆæ®‹å·®è¿æ¥ä¸ä¸­ç­‰è§„æ¨¡æ•°æ®é›†ä¼˜åŒ–\n",
    "    åç§°å«ä¹‰: Bird (é¸Ÿç±») + ResNet (æ®‹å·®ç½‘ç»œ)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(BirdResNet, self).__init__()\n",
    "\n",
    "        # åˆå§‹å·ç§¯å±‚\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # ç¬¬ä¸€ç»„å·ç§¯å±‚ï¼ˆåŒ…å«æ®‹å·®å—ï¼‰\n",
    "        self.res_block1 = ResidualBlock(32, 64, stride=1)\n",
    "\n",
    "        # ç¬¬äºŒç»„å·ç§¯å±‚\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # ç¬¬äºŒç»„å·ç§¯å±‚ï¼ˆåŒ…å«æ®‹å·®å—ï¼‰\n",
    "        self.res_block2 = ResidualBlock(128, 128, stride=1)\n",
    "\n",
    "        # ç¬¬ä¸‰ç»„å·ç§¯å±‚\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # ç¬¬ä¸‰ç»„å·ç§¯å±‚ï¼ˆåŒ…å«æ®‹å·®å—ï¼‰\n",
    "        self.res_block3 = ResidualBlock(256, 256, stride=1)\n",
    "\n",
    "        # ç¬¬å››ç»„å·ç§¯å±‚ï¼ˆæ·±å±‚ç‰¹å¾ï¼‰\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "\n",
    "        # æ›´å¼ºçš„æ­£åˆ™åŒ–\n",
    "        self.dropout_conv = nn.Dropout2d(p=0.3)\n",
    "        self.dropout_fc = nn.Dropout(p=0.5)\n",
    "\n",
    "        # å…¨è¿æ¥å±‚ï¼ˆé€‚åº¦å‡å°è§„æ¨¡ï¼‰\n",
    "        self.fc1 = nn.Linear(512 * 7 * 7, 512)\n",
    "        self.fc1_bn = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc2_bn = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # åˆå§‹å·ç§¯å—\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)  # 112x112\n",
    "\n",
    "        # ç¬¬ä¸€ç»„å·ç§¯ + æ®‹å·®å—\n",
    "        x = self.res_block1(x)  # æ®‹å·®è¿æ¥\n",
    "        x = F.max_pool2d(x, 2)  # 56x56\n",
    "\n",
    "        # ç¬¬äºŒç»„å·ç§¯ + æ®‹å·®å—\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.res_block2(x)  # æ®‹å·®è¿æ¥\n",
    "        x = self.dropout_conv(x)\n",
    "        x = F.max_pool2d(x, 2)  # 28x28\n",
    "\n",
    "        # ç¬¬ä¸‰ç»„å·ç§¯ + æ®‹å·®å—\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.res_block3(x)  # æ®‹å·®è¿æ¥\n",
    "        x = F.max_pool2d(x, 2)  # 14x14\n",
    "\n",
    "        # ç¬¬å››ç»„å·ç§¯\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.max_pool2d(x, 2)  # 7x7\n",
    "\n",
    "        # å±•å¹³\n",
    "        x = x.view(-1, 512 * 7 * 7)\n",
    "\n",
    "        # å…¨è¿æ¥å±‚\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = self.dropout_fc(x)\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0db15896-29ec-48ef-a936-51f5c3c10cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingLogger:\n",
    "    \"\"\"è®­ç»ƒæ—¥å¿—è®°å½•å™¨\"\"\"\n",
    "    def __init__(self, log_path):\n",
    "        self.log_path = log_path\n",
    "        self.console = sys.stdout\n",
    "        self.log_file = open(log_path, 'w', encoding='utf-8')\n",
    "\n",
    "    def write(self, message):\n",
    "        self.console.write(message)\n",
    "        self.log_file.write(message)\n",
    "        self.log_file.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        self.console.flush()\n",
    "        self.log_file.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.log_file.close()\n",
    "\n",
    "\n",
    "def setup_logging(log_path):\n",
    "    \"\"\"å¯ç”¨æ—¥å¿—è®°å½•\"\"\"\n",
    "    logger = TrainingLogger(log_path)\n",
    "    sys.stdout = logger\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ad20c27-2159-4913-b8a6-4ed2c082729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader_with_error_handling(path):\n",
    "    \"\"\"å¸¦é”™è¯¯å¤„ç†çš„å›¾ç‰‡åŠ è½½\"\"\"\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ æ— æ³•åŠ è½½å›¾ç‰‡: {path}, é”™è¯¯: {e}\")\n",
    "        return Image.new('RGB', (224, 224), color='white')\n",
    "\n",
    "\n",
    "def check_and_clean_dataset(data_path):\n",
    "    \"\"\"æ£€æŸ¥å¹¶æ¸…ç†æŸåå›¾ç‰‡\"\"\"\n",
    "    print(\"æ­£åœ¨æ£€æŸ¥æ•°æ®é›†å®Œæ•´æ€§...\")\n",
    "    corrupted = []\n",
    "    for mode in ['train', 'test']:\n",
    "        dir_path = os.path.join(data_path, mode)\n",
    "        for cls in os.listdir(dir_path):\n",
    "            cls_path = os.path.join(dir_path, cls)\n",
    "            for f in os.listdir(cls_path):\n",
    "                if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    path = os.path.join(cls_path, f)\n",
    "                    try:\n",
    "                        Image.open(path).verify()\n",
    "                    except:\n",
    "                        corrupted.append(path)\n",
    "                        os.rename(path, path + \".corrupted\")\n",
    "    if corrupted:\n",
    "        print(f\"å…±å‘ç° {len(corrupted)} å¼ æŸåå›¾ç‰‡ï¼Œå·²æ ‡è®°ä¸º .corrupted\")\n",
    "    else:\n",
    "        print(\"æ•°æ®é›†æ£€æŸ¥é€šè¿‡ âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55b2c248-9380-4a84-a000-0c621c46618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(data_path, batch_size_train=32, batch_size_test=64):\n",
    "    \"\"\"æ„å»ºDataLoader\"\"\"\n",
    "    check_and_clean_dataset(data_path)\n",
    "\n",
    "    transform_train = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(0.5),\n",
    "        torchvision.transforms.RandomRotation(10),\n",
    "        torchvision.transforms.ColorJitter(0.1, 0.1, 0.1, 0.05),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                         [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    transform_test = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                         [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_ds = torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_path, 'train'), transform=transform_train, loader=pil_loader_with_error_handling)\n",
    "    test_ds = torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_path, 'test'), transform=transform_test, loader=pil_loader_with_error_handling)\n",
    "\n",
    "    print(f\"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡: {len(train_ds)} è®­ç»ƒæ ·æœ¬, {len(test_ds)} æµ‹è¯•æ ·æœ¬, ç±»åˆ«æ•°: {len(train_ds.classes)}\")\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size_train, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_ds, batch_size_test, shuffle=False)\n",
    "    return train_loader, test_loader, len(train_ds.classes), train_ds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f326cc95-9598-4d23-be85-434d573cc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    loss_total, correct, total = 0, 0, 0\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch}\")\n",
    "    for data, target in pbar:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_total += loss.item()\n",
    "        pred = output.argmax(1)\n",
    "        correct += pred.eq(target).sum().item()\n",
    "        total += data.size(0)\n",
    "        pbar.set_postfix(loss=loss.item(), acc=f\"{100*correct/total:.2f}%\")\n",
    "\n",
    "    return loss_total / len(loader), 100 * correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, device, loader):\n",
    "    model.eval()\n",
    "    correct, loss_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss_total += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "    return loss_total / len(loader.dataset), 100 * correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc2e680-ac1f-423d-80be-0248e3c84854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f2a0ea0-428d-4c23-b954-27a46a0169ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ å›¾ç‰‡è¯»å–å¤±è´¥ {path}: {e}\")\n",
    "        return Image.new('RGB', (224,224), color='white')\n",
    "\n",
    "def get_loaders(data_dir, batch_size=64):\n",
    "    transform_train = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                         [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    transform_test = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                         [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'train'), transform=transform_train, loader=pil_loader)\n",
    "    test_dataset = torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'test'), transform=transform_test, loader=pil_loader)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, len(train_dataset.classes), train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f6dc40d-d588-4915-b849-1a02d916b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, device, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for data, target in tqdm(loader, desc=\"è®­ç»ƒä¸­\"):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(1)\n",
    "        correct += pred.eq(target).sum().item()\n",
    "        total += len(data)\n",
    "    return total_loss/len(loader), 100 * correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, device, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            total_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            total += len(data)\n",
    "    return total_loss/len(loader.dataset), 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8eac8cf6-5460-4617-b21b-fdbd30a57bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…± 10 ç±»\n"
     ]
    }
   ],
   "source": [
    "data_path = r\".\\Dataset\"\n",
    "train_loader, test_loader, num_classes, class_names = get_loaders(data_path)\n",
    "print(f\"âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…± {num_classes} ç±»\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca2d0bd-43a2-4378-8dc8-fc3bcb7df351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
