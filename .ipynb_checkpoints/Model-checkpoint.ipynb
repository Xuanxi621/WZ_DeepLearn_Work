{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3459e2c8-34dd-4fde-8e19-36f6ef5cd31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 当前设备：cuda\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import random\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ 当前设备：{device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1d7a1-cb00-49ce-bfac-b2b32145f0de",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0a48b8-c5ee-4f09-bd51-c39b70bdc935",
   "metadata": {},
   "source": [
    "### BirdCNN - 基础卷积神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46f4f41e-be3d-4915-8403-5a504bc6db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    鸟类识别CNN模型\n",
    "    适配224x224输入尺寸，支持自定义类别数量\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(BirdCNN, self).__init__()\n",
    "\n",
    "        # ===== 卷积层堆叠 =====\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, 1, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout2d(p=0.25)\n",
    "\n",
    "        # ===== 全连接层 =====\n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n",
    "        self.fc1_bn = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc2_bn = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # --- 卷积块1 ---\n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), 2)\n",
    "        # --- 卷积块2 ---\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), 2)\n",
    "        # --- 卷积块3 ---\n",
    "        x = self.dropout(F.max_pool2d(F.relu(self.bn3(self.conv3(x))), 2))\n",
    "        # --- 卷积块4 ---\n",
    "        x = F.max_pool2d(F.relu(self.bn4(self.conv4(x))), 2)\n",
    "        x = F.max_pool2d(x, 2)  # -> [batch, 128, 7, 7]\n",
    "\n",
    "        # --- 展平 + 全连接 ---\n",
    "        x = x.view(-1, 128 * 7 * 7)\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e5a98-f764-4d3a-9bc1-7ef05df9a1ec",
   "metadata": {},
   "source": [
    "### BirdCNN_Optimal — 针对中小规模数据集优化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23601966-dae3-4f8a-9c51-061bf280d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCNN_Optimal(nn.Module):\n",
    "    \"\"\"\n",
    "    针对3000左右张图片的优化模型 - 避免过拟合同时增强特征提取\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(BirdCNN_Optimal, self).__init__()\n",
    "\n",
    "        # ===== 卷积模块 =====\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv3_extra = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        self.bn3_extra = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, 1, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout_conv = nn.Dropout2d(p=0.3)\n",
    "        self.dropout_fc = nn.Dropout(p=0.5)\n",
    "\n",
    "        # ===== 全连接层 =====\n",
    "        self.fc1 = nn.Linear(256 * 7 * 7, 512)\n",
    "        self.fc1_bn = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc2_bn = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), 2)\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn3_extra(self.conv3_extra(x)))\n",
    "        x = self.dropout_conv(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = F.max_pool2d(F.relu(self.bn4(self.conv4(x))), 4)\n",
    "        x = x.view(-1, 256 * 7 * 7)\n",
    "\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = self.dropout_fc(x)\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f603c3-cb6e-45cb-89a7-f5504e32ae87",
   "metadata": {},
   "source": [
    "### BirdResNet — 残差结构CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46400495-1246-461d-9e53-8b83535a5ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    残差块 - 保持输入输出尺寸相同\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        # 主路径\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # 捷径路径（如果需要调整尺寸）\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "        self.dropout = nn.Dropout2d(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 主路径\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # 捷径路径\n",
    "        shortcut = self.shortcut(x)\n",
    "\n",
    "        # 残差连接\n",
    "        out += shortcut\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class BirdResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    鸟类识别残差网络 - 结合残差连接与中等规模数据集优化\n",
    "    名称含义: Bird (鸟类) + ResNet (残差网络)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(BirdResNet, self).__init__()\n",
    "\n",
    "        # 初始卷积层\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # 第一组卷积层（包含残差块）\n",
    "        self.res_block1 = ResidualBlock(32, 64, stride=1)\n",
    "\n",
    "        # 第二组卷积层\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # 第二组卷积层（包含残差块）\n",
    "        self.res_block2 = ResidualBlock(128, 128, stride=1)\n",
    "\n",
    "        # 第三组卷积层\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # 第三组卷积层（包含残差块）\n",
    "        self.res_block3 = ResidualBlock(256, 256, stride=1)\n",
    "\n",
    "        # 第四组卷积层（深层特征）\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "\n",
    "        # 更强的正则化\n",
    "        self.dropout_conv = nn.Dropout2d(p=0.3)\n",
    "        self.dropout_fc = nn.Dropout(p=0.5)\n",
    "\n",
    "        # 全连接层（适度减小规模）\n",
    "        self.fc1 = nn.Linear(512 * 7 * 7, 512)\n",
    "        self.fc1_bn = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc2_bn = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始卷积块\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)  # 112x112\n",
    "\n",
    "        # 第一组卷积 + 残差块\n",
    "        x = self.res_block1(x)  # 残差连接\n",
    "        x = F.max_pool2d(x, 2)  # 56x56\n",
    "\n",
    "        # 第二组卷积 + 残差块\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.res_block2(x)  # 残差连接\n",
    "        x = self.dropout_conv(x)\n",
    "        x = F.max_pool2d(x, 2)  # 28x28\n",
    "\n",
    "        # 第三组卷积 + 残差块\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.res_block3(x)  # 残差连接\n",
    "        x = F.max_pool2d(x, 2)  # 14x14\n",
    "\n",
    "        # 第四组卷积\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.max_pool2d(x, 2)  # 7x7\n",
    "\n",
    "        # 展平\n",
    "        x = x.view(-1, 512 * 7 * 7)\n",
    "\n",
    "        # 全连接层\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = self.dropout_fc(x)\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0db15896-29ec-48ef-a936-51f5c3c10cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingLogger:\n",
    "    \"\"\"训练日志记录器\"\"\"\n",
    "    def __init__(self, log_path):\n",
    "        self.log_path = log_path\n",
    "        self.console = sys.stdout\n",
    "        self.log_file = open(log_path, 'w', encoding='utf-8')\n",
    "\n",
    "    def write(self, message):\n",
    "        self.console.write(message)\n",
    "        self.log_file.write(message)\n",
    "        self.log_file.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        self.console.flush()\n",
    "        self.log_file.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.log_file.close()\n",
    "\n",
    "\n",
    "def setup_logging(log_path):\n",
    "    \"\"\"启用日志记录\"\"\"\n",
    "    logger = TrainingLogger(log_path)\n",
    "    sys.stdout = logger\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ad20c27-2159-4913-b8a6-4ed2c082729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader_with_error_handling(path):\n",
    "    \"\"\"带错误处理的图片加载\"\"\"\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 无法加载图片: {path}, 错误: {e}\")\n",
    "        return Image.new('RGB', (224, 224), color='white')\n",
    "\n",
    "\n",
    "def check_and_clean_dataset(data_path):\n",
    "    \"\"\"检查并清理损坏图片\"\"\"\n",
    "    print(\"正在检查数据集完整性...\")\n",
    "    corrupted = []\n",
    "    for mode in ['train', 'test']:\n",
    "        dir_path = os.path.join(data_path, mode)\n",
    "        for cls in os.listdir(dir_path):\n",
    "            cls_path = os.path.join(dir_path, cls)\n",
    "            for f in os.listdir(cls_path):\n",
    "                if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    path = os.path.join(cls_path, f)\n",
    "                    try:\n",
    "                        Image.open(path).verify()\n",
    "                    except:\n",
    "                        corrupted.append(path)\n",
    "                        os.rename(path, path + \".corrupted\")\n",
    "    if corrupted:\n",
    "        print(f\"共发现 {len(corrupted)} 张损坏图片，已标记为 .corrupted\")\n",
    "    else:\n",
    "        print(\"数据集检查通过 ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55b2c248-9380-4a84-a000-0c621c46618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(data_path, batch_size_train=32, batch_size_test=64):\n",
    "    \"\"\"构建DataLoader\"\"\"\n",
    "    check_and_clean_dataset(data_path)\n",
    "\n",
    "    transform_train = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(0.5),\n",
    "        torchvision.transforms.RandomRotation(10),\n",
    "        torchvision.transforms.ColorJitter(0.1, 0.1, 0.1, 0.05),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                         [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    transform_test = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                         [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_ds = torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_path, 'train'), transform=transform_train, loader=pil_loader_with_error_handling)\n",
    "    test_ds = torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_path, 'test'), transform=transform_test, loader=pil_loader_with_error_handling)\n",
    "\n",
    "    print(f\"📊 数据集统计: {len(train_ds)} 训练样本, {len(test_ds)} 测试样本, 类别数: {len(train_ds.classes)}\")\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size_train, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_ds, batch_size_test, shuffle=False)\n",
    "    return train_loader, test_loader, len(train_ds.classes), train_ds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f326cc95-9598-4d23-be85-434d573cc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    loss_total, correct, total = 0, 0, 0\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch}\")\n",
    "    for data, target in pbar:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_total += loss.item()\n",
    "        pred = output.argmax(1)\n",
    "        correct += pred.eq(target).sum().item()\n",
    "        total += data.size(0)\n",
    "        pbar.set_postfix(loss=loss.item(), acc=f\"{100*correct/total:.2f}%\")\n",
    "\n",
    "    return loss_total / len(loader), 100 * correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, device, loader):\n",
    "    model.eval()\n",
    "    correct, loss_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss_total += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "    return loss_total / len(loader.dataset), 100 * correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc2e680-ac1f-423d-80be-0248e3c84854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f2a0ea0-428d-4c23-b954-27a46a0169ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 图片读取失败 {path}: {e}\")\n",
    "        return Image.new('RGB', (224,224), color='white')\n",
    "\n",
    "def get_loaders(data_dir, batch_size=64):\n",
    "    transform_train = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                         [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    transform_test = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                         [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'train'), transform=transform_train, loader=pil_loader)\n",
    "    test_dataset = torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'test'), transform=transform_test, loader=pil_loader)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, len(train_dataset.classes), train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f6dc40d-d588-4915-b849-1a02d916b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, device, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for data, target in tqdm(loader, desc=\"训练中\"):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(1)\n",
    "        correct += pred.eq(target).sum().item()\n",
    "        total += len(data)\n",
    "    return total_loss/len(loader), 100 * correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, device, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            total_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            total += len(data)\n",
    "    return total_loss/len(loader.dataset), 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8eac8cf6-5460-4617-b21b-fdbd30a57bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 数据集加载完成，共 10 类\n"
     ]
    }
   ],
   "source": [
    "data_path = r\".\\Dataset\"\n",
    "train_loader, test_loader, num_classes, class_names = get_loaders(data_path)\n",
    "print(f\"✅ 数据集加载完成，共 {num_classes} 类\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca2d0bd-43a2-4378-8dc8-fc3bcb7df351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
