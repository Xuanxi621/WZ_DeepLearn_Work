from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image
import io
import uvicorn
import os
from typing import List
import json

# é¸Ÿç±»ç±»åˆ«åç§°ï¼ˆæ ¹æ®æ•°æ®é›†ç»“æ„ï¼‰
BIRD_CLASSES = [
    "Black-footed_Albatross",
    "Brewer_Blackbird", 
    "Crested_Auklet",
    "Groove_billed_Ani",
    "Laysan_Albatross",
    "Least_Auklet",
    "Parakeet_Auklet",
    "Red_winged_Blackbird",
    "Rhinoceros_Auklet",
    "Sooty_Albatross"
]

# æ¨¡å‹å®šä¹‰ï¼ˆä»Model.ipynbå¤åˆ¶ï¼‰
class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels)
            )
        self.dropout = nn.Dropout2d(p=0.2)

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out = self.dropout(out)
        shortcut = self.shortcut(x)
        out += shortcut
        out = F.relu(out)
        return out

class BirdResNet(nn.Module):
    def __init__(self, num_classes=10):
        super(BirdResNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)
        self.bn1 = nn.BatchNorm2d(32)
        self.res_block1 = ResidualBlock(32, 64, stride=1)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(128)
        self.res_block2 = ResidualBlock(128, 128, stride=1)
        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)
        self.bn3 = nn.BatchNorm2d(256)
        self.res_block3 = ResidualBlock(256, 256, stride=1)
        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)
        self.bn4 = nn.BatchNorm2d(512)
        self.dropout_conv = nn.Dropout2d(p=0.3)
        self.dropout_fc = nn.Dropout(p=0.5)
        self.fc1 = nn.Linear(512 * 7 * 7, 512)
        self.fc1_bn = nn.BatchNorm1d(512)
        self.fc2 = nn.Linear(512, 256)
        self.fc2_bn = nn.BatchNorm1d(256)
        self.fc3 = nn.Linear(256, num_classes)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.max_pool2d(x, 2)
        x = self.res_block1(x)
        x = F.max_pool2d(x, 2)
        x = F.relu(self.bn2(self.conv2(x)))
        x = self.res_block2(x)
        x = self.dropout_conv(x)
        x = F.max_pool2d(x, 2)
        x = F.relu(self.bn3(self.conv3(x)))
        x = self.res_block3(x)
        x = F.max_pool2d(x, 2)
        x = F.relu(self.bn4(self.conv4(x)))
        x = F.max_pool2d(x, 2)
        x = x.view(-1, 512 * 7 * 7)
        x = F.relu(self.fc1_bn(self.fc1(x)))
        x = self.dropout_fc(x)
        x = F.relu(self.fc2_bn(self.fc2(x)))
        x = self.fc3(x)
        return F.log_softmax(x, dim=1)

# åˆå§‹åŒ–FastAPIåº”ç”¨
app = FastAPI(title="é¸Ÿç±»è¯†åˆ«API", description="ä½¿ç”¨BirdResNetæ¨¡å‹è¯†åˆ«é¸Ÿç±»ç§ç±»", version="1.0.0")

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = None

# å›¾ç‰‡é¢„å¤„ç†
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

def load_model():
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    global model
    try:
        model = BirdResNet(num_classes=len(BIRD_CLASSES))
        model_path = "BirdResNet_best.pth"
        
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ {model_path} ä¸å­˜åœ¨")
        
        # åŠ è½½æ¨¡å‹æƒé‡
        model.load_state_dict(torch.load(model_path, map_location=device))
        model.to(device)
        model.eval()
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œè®¾å¤‡: {device}")
        return True
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹"""
    print("ğŸš€ æ­£åœ¨å¯åŠ¨é¸Ÿç±»è¯†åˆ«API...")
    if not load_model():
        print("âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨")

@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å›APIä¿¡æ¯"""
    return {
        "message": "é¸Ÿç±»è¯†åˆ«API",
        "version": "1.0.0",
        "model_loaded": model is not None,
        "device": str(device),
        "supported_classes": BIRD_CLASSES
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {
        "status": "healthy",
        "model_loaded": model is not None,
        "device": str(device)
    }

@app.post("/predict")
async def predict_bird(file: UploadFile = File(...)):
    """
    ä¸Šä¼ å›¾ç‰‡å¹¶é¢„æµ‹é¸Ÿç±»ç§ç±»
    
    Args:
        file: ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶
        
    Returns:
        JSONå“åº”åŒ…å«é¢„æµ‹ç»“æœ
    """
    if model is None:
        raise HTTPException(status_code=500, detail="æ¨¡å‹æœªåŠ è½½ï¼Œè¯·æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€")
    
    # æ£€æŸ¥æ–‡ä»¶ç±»å‹
    if not file.content_type.startswith('image/'):
        raise HTTPException(status_code=400, detail="è¯·ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶")
    
    try:
        # è¯»å–å›¾ç‰‡
        image_data = await file.read()
        image = Image.open(io.BytesIO(image_data))
        
        # è½¬æ¢ä¸ºRGBæ ¼å¼
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # é¢„å¤„ç†å›¾ç‰‡
        input_tensor = transform(image).unsqueeze(0).to(device)
        
        # è¿›è¡Œé¢„æµ‹
        with torch.no_grad():
            outputs = model(input_tensor)
            probabilities = F.softmax(outputs, dim=1)
            confidence, predicted = torch.max(probabilities, 1)
            
            # è·å–æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
            all_probs = probabilities[0].cpu().numpy()
            
        # æ„å»ºç»“æœ
        predicted_class = BIRD_CLASSES[predicted.item()]
        confidence_score = confidence.item()
        
        # è·å–å‰5ä¸ªæœ€å¯èƒ½çš„ç±»åˆ«
        top5_indices = torch.topk(probabilities, 5, dim=1)[1][0].cpu().numpy()
        top5_results = []
        
        for idx in top5_indices:
            top5_results.append({
                "class": BIRD_CLASSES[idx],
                "confidence": float(all_probs[idx])
            })
        
        return JSONResponse(content={
            "success": True,
            "predicted_class": predicted_class,
            "confidence": confidence_score,
            "top5_predictions": top5_results,
            "filename": file.filename,
            "image_size": image.size
        })
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é¢„æµ‹å¤±è´¥: {str(e)}")

@app.post("/predict_batch")
async def predict_batch(files: List[UploadFile] = File(...)):
    """
    æ‰¹é‡é¢„æµ‹å¤šå¼ å›¾ç‰‡
    
    Args:
        files: ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨
        
    Returns:
        JSONå“åº”åŒ…å«æ¯å¼ å›¾ç‰‡çš„é¢„æµ‹ç»“æœ
    """
    if model is None:
        raise HTTPException(status_code=500, detail="æ¨¡å‹æœªåŠ è½½ï¼Œè¯·æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€")
    
    if len(files) > 10:  # é™åˆ¶æ‰¹é‡ä¸Šä¼ æ•°é‡
        raise HTTPException(status_code=400, detail="æ‰¹é‡ä¸Šä¼ æœ€å¤šæ”¯æŒ10å¼ å›¾ç‰‡")
    
    results = []
    
    for file in files:
        try:
            # æ£€æŸ¥æ–‡ä»¶ç±»å‹
            if not file.content_type.startswith('image/'):
                results.append({
                    "filename": file.filename,
                    "success": False,
                    "error": "ä¸æ˜¯æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶"
                })
                continue
            
            # è¯»å–å’Œé¢„å¤„ç†å›¾ç‰‡
            image_data = await file.read()
            image = Image.open(io.BytesIO(image_data))
            
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            input_tensor = transform(image).unsqueeze(0).to(device)
            
            # é¢„æµ‹
            with torch.no_grad():
                outputs = model(input_tensor)
                probabilities = F.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
            
            predicted_class = BIRD_CLASSES[predicted.item()]
            confidence_score = confidence.item()
            
            results.append({
                "filename": file.filename,
                "success": True,
                "predicted_class": predicted_class,
                "confidence": confidence_score,
                "image_size": image.size
            })
            
        except Exception as e:
            results.append({
                "filename": file.filename,
                "success": False,
                "error": str(e)
            })
    
    return JSONResponse(content={
        "success": True,
        "total_files": len(files),
        "results": results
    })

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
